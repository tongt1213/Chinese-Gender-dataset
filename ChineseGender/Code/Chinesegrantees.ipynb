{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16375177-0fd4-4213-b710-388bf7dbea73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File successfully processed and saved as /Users/tongtong/Documents/python/grantees_raw_temp.csv\n"
     ]
    }
   ],
   "source": [
    "#data preprocessing \n",
    "#Split first names and last names, coping with Chinese multiple surname.\n",
    "import pandas as pd\n",
    "\n",
    "input_file = '/.../grantees_raw.csv'\n",
    "output_file = '/.../grantees_raw_temp.csv'\n",
    "\n",
    "compound_surnames_dict = {\n",
    "    1: \"欧阳\", 2: \"太史\", 3: \"端木\", 4: \"上官\", 5: \"司马\", 6: \"东方\", 7: \"独孤\", 8: \"南宫\", 9: \"万俟\", 10: \"闻人\",\n",
    "    11: \"夏侯\", 12: \"诸葛\", 13: \"尉迟\", 14: \"公羊\", 15: \"赫连\", 16: \"澹台\", 17: \"皇甫\", 18: \"宗政\", 19: \"濮阳\",\n",
    "    20: \"公冶\", 21: \"太叔\", 22: \"申屠\", 23: \"公孙\", 24: \"慕容\", 25: \"仲孙\", 26: \"钟离\", 27: \"长孙\", 28: \"宇文\",\n",
    "    29: \"司徒\", 30: \"鲜于\", 31: \"司空\", 32: \"闾丘\", 33: \"子车\", 34: \"亓官\", 35: \"司寇\", 36: \"巫马\", 37: \"公西\",\n",
    "    38: \"颛孙\", 39: \"壤驷\", 40: \"公良\", 41: \"漆雕\", 42: \"乐正\", 43: \"宰父\", 44: \"谷梁\", 45: \"拓跋\", 46: \"夹谷\",\n",
    "    47: \"轩辕\", 48: \"令狐\", 49: \"段干\", 50: \"百里\", 51: \"呼延\", 52: \"东郭\", 53: \"南门\", 54: \"羊舌\", 55: \"微生\",\n",
    "    56: \"公户\", 57: \"公玉\", 58: \"公仪\", 59: \"梁丘\", 60: \"公仲\", 61: \"公上\", 62: \"公门\", 63: \"公山\", 64: \"公坚\",\n",
    "    65: \"左丘\", 66: \"公伯\", 67: \"西门\", 68: \"公祖\", 69: \"第五\", 70: \"公乘\", 71: \"贯丘\", 72: \"公皙\", 73: \"南荣\",\n",
    "    74: \"东里\", 75: \"东宫\", 76: \"仲长\", 77: \"子书\", 78: \"子桑\", 79: \"即墨\", 80: \"达奚\", 81: \"褚师\", 82: \"吴铭\"\n",
    "}\n",
    "compound_surnames = set(compound_surnames_dict.values())\n",
    "\n",
    "def process_name(name):\n",
    "    name = str(name)  \n",
    "    for surname in compound_surnames:\n",
    "        if name.startswith(surname):\n",
    "            return surname, name[len(surname):]\n",
    "    return name[0], name[1:]\n",
    "\n",
    "try:\n",
    "    data = pd.read_csv(input_file, delimiter='\\t', encoding='utf-8')\n",
    "\n",
    "    if data.columns[0] == 'name':\n",
    "        data[['family', 'given']] = data.iloc[:, 0].apply(lambda x: pd.Series(process_name(x)))\n",
    "    else:\n",
    "        print(\"The first column is not named 'name'. Please verify the data.\")\n",
    "\n",
    "    data.to_csv(output_file, sep='\\t', index=False, encoding='utf-8')\n",
    "    \n",
    "    print(f\"File successfully processed and saved as {output_file}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"The file at {input_file} was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4de6dc81-df8c-4f7b-ab40-2fe8f9d8be8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File successfully cleaned and saved as /Users/tongtong/Documents/python/grantees_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "#data preprocessing \n",
    "#Delete lines containing letters, numbers, and punctuation.\n",
    "#Limit the name length to 4.\n",
    "import re\n",
    "\n",
    "input_file = '/.../grantees_raw_temp.csv'\n",
    "output_file = '/.../grantees_cleaned.csv'\n",
    "\n",
    "def contains_invalid_characters(text):\n",
    "    if pd.isna(text):  \n",
    "        return False\n",
    "    return bool(re.search(r'[^\\u4e00-\\u9fa5]', str(text)))  \n",
    "\n",
    "try:\n",
    "    data = pd.read_csv(input_file, delimiter='\\t', encoding='utf-8')\n",
    "    data = data[~data['name'].apply(contains_invalid_characters)]\n",
    "    data = data.dropna(subset=['given'])\n",
    "    data = data[data['given'].str.len().between(1, 2)]\n",
    "    data.to_csv(output_file, sep='\\t', index=False, encoding='utf-8')\n",
    "    \n",
    "    print(f\"File successfully cleaned and saved as {output_file}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"The file at {input_file} was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6f57c8f-576a-4e5c-89db-e161b68b1089",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(22262) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypinyin in /opt/anaconda3/lib/python3.12/site-packages (0.51.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#install Pinyin converting tool:https://pypi.org/project/pypinyin/\n",
    "pip install pypinyin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e4f6386b-69c1-4fc1-9197-6118d29af621",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting to Pinyin: 100%|████████████| 99729/99729 [00:01<00:00, 98212.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File successfully processed and saved as /Users/tongtong/Documents/python/grantees_with_pinyin.csv\n"
     ]
    }
   ],
   "source": [
    "#adjusting incorrect pinyin converting rules from pypinyin\n",
    "import pypinyin\n",
    "from tqdm import tqdm\n",
    "\n",
    "# new rules\n",
    "corrections = {\n",
    "    '思': 'si', \n",
    "    '育': 'yu',\n",
    "    '若': 'ruo',\n",
    "    '敦': 'dun',\n",
    "    '朴': 'pu',\n",
    "    '露': 'lu',\n",
    "    '陆': 'lu',\n",
    "    '男': 'nan',\n",
    "    '南': 'nan',\n",
    "    '楠': 'nan',\n",
    "    '钠': 'na',\n",
    "    '娜': 'na',\n",
    "    '拓': 'tuo',\n",
    "    '觉': 'jue',\n",
    "}\n",
    "\n",
    "def convert_to_pinyin(text):\n",
    "    pinyin_list = pypinyin.lazy_pinyin(text)\n",
    "    corrected_pinyin = []\n",
    "    for char, pinyin_char in zip(text, pinyin_list):\n",
    "        if char in corrections:\n",
    "            corrected_pinyin.append(corrections[char])  # 使用修正规则\n",
    "        else:\n",
    "            corrected_pinyin.append(pinyin_char)  # 使用默认拼音\n",
    "    return ''.join(corrected_pinyin)\n",
    "\n",
    "input_file = '/.../grantees_cleaned.csv'\n",
    "output_file = '/.../grantees_with_pinyin.csv'\n",
    "\n",
    "try:\n",
    "    data = pd.read_csv(input_file, delimiter='\\t', encoding='utf-8')\n",
    "\n",
    "    tqdm.pandas(desc=\"Converting to Pinyin\")\n",
    "    data['givenEn'] = data['given'].progress_apply(lambda x: convert_to_pinyin(str(x)) if pd.notna(x) else '')\n",
    "\n",
    "    data.to_csv(output_file, sep='\\t', index=False, encoding='utf-8')\n",
    "    print(f\"File successfully processed and saved as {output_file}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"The file at {input_file} was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "84e1548c-ea94-49f4-8b53-209074e3c523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "修复后的列名： Index(['name', 'gender', 'birthyear', 'psncode', 'family', 'given', 'givenEn'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#adjusting headers of the grantees dataset\n",
    "\n",
    "file_path = '/Users/tongtong/Documents/python/grantees_with_pinyin.csv'\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "print(\"修复后的列名：\", df.columns)\n",
    "df.rename(columns={'name': 'name_x'}, inplace=True)\n",
    "df.to_csv(file_path, sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f3b273a3-942b-4bae-b5d6-b52989cd79a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "匹配结果已保存到 /Users/tongtong/Documents/python/matched_results.csv\n"
     ]
    }
   ],
   "source": [
    "#merge with genderize.io results\n",
    "\n",
    "file1_path = '/.../gender_finalresults.csv'#result of genderize.io\n",
    "file2_path = '/.../grantees_with_pinyin.csv'\n",
    "output_file_path = '/.../matched_results.csv'\n",
    "\n",
    "try:\n",
    "    gender_finalresults = pd.read_csv(file1_path, delimiter=',')  # 假设第一个文件是逗号分隔\n",
    "    grantees_with_pinyin = pd.read_csv(file2_path, delimiter='\\t')  # 第二个文件为制表符分隔\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error reading the file: {e}\")\n",
    "    exit()\n",
    "\n",
    "gender_finalresults['name_lower'] = gender_finalresults['name'].str.lower()\n",
    "grantees_with_pinyin['givenEn_lower'] = grantees_with_pinyin['givenEn'].str.lower()\n",
    "\n",
    "merged_df = pd.merge(\n",
    "    grantees_with_pinyin,\n",
    "    gender_finalresults.drop_duplicates(subset='name_lower'),  # 去重，避免一对多\n",
    "    left_on='givenEn_lower',\n",
    "    right_on='name_lower',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "merged_df.drop(columns=['name_lower', 'givenEn_lower'], inplace=True)\n",
    "merged_df.to_csv(output_file_path, index=False, encoding='utf-8', sep='\\t')\n",
    "print(f\"匹配结果已保存到 {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8aa28cbb-1a95-4337-943d-5f2a48972124",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/51/w5vwjwvj7wl_p7txgvf8ypbr0000gn/T/ipykernel_24722/667417447.py:10: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  gudong_after_df = pd.read_csv(gudong_after_file, sep='\\t', on_bad_lines='skip')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功读取股东数据，列名如下： Index(['id', 'orig_name', 'gender', 'b_year', '姓', '名', 'lname', 'fname',\n",
      "       '拼音总数量', '拼音男性数量', '拼音男性概率', '汉字总数量', '汉字男性数量', '汉字男性概率'],\n",
      "      dtype='object')\n",
      "成功读取真值数据，列名如下： Index(['name_x', 'gender', 'birthyear', 'psncode', 'family', 'given',\n",
      "       'givenEn', 'name', 'country_id', 'gender_genderize', 'probability',\n",
      "       'count'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|███████████████████| 99729/99729 [00:00<00:00, 106532.92rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理后的前10行：\n",
      "  name_x gender  birthyear   psncode family given    givenEn       name  \\\n",
      "0    苏育嵩      男     1900.0  398316.0      苏    育嵩     yusong     YUSONG   \n",
      "1    孙福玉      男     1900.0  403025.0      孙    福玉       fuyu       FUYU   \n",
      "2    张慧友      男     1900.0  396915.0      张    慧友     huiyou        NaN   \n",
      "3    张赛珍      女     1900.0  398576.0      张    赛珍    saizhen    SAIZHEN   \n",
      "4    陈禄生      男     1900.0  403814.0      陈    禄生    lusheng    LUSHENG   \n",
      "5    庄鸿寿      男     1900.0  403066.0      庄    鸿寿   hongshou        NaN   \n",
      "6    孙大章      男     1900.0  403903.0      孙    大章    dazhang    DAZHANG   \n",
      "7    陈偕雄      男     1900.0  385882.0      陈    偕雄   xiexiong        NaN   \n",
      "8    孙钟秀      男     1900.0  385918.0      孙    钟秀   zhongxiu   ZHONGXIU   \n",
      "9    宋焕成      男     1900.0  388352.0      宋    焕成  huancheng  HUANCHENG   \n",
      "\n",
      "  country_id gender_genderize  probability  count  汉字总数量    汉字男性概率   拼音总数量  \\\n",
      "0         CN             male         0.83    6.0    2.0  1.000000  1927.0   \n",
      "1         CN           female         0.50    8.0  582.0  0.752577  1893.0   \n",
      "2        NaN              NaN          NaN    NaN    9.0  1.000000   512.0   \n",
      "3         CN           female         1.00    1.0  315.0  0.003175   356.0   \n",
      "4         CN             male         1.00    2.0   96.0  1.000000  1132.0   \n",
      "5        NaN              NaN          NaN    NaN   15.0  0.933333   226.0   \n",
      "6         CN             male         1.00    1.0  193.0  0.984456   334.0   \n",
      "7        NaN              NaN          NaN    NaN    1.0  1.000000    20.0   \n",
      "8         CN           female         0.50    2.0   62.0  0.451613  1018.0   \n",
      "9         CN           female         1.00    1.0  469.0  0.923241   749.0   \n",
      "\n",
      "     拼音男性概率  genderize_predict_male  \n",
      "0  0.920602                    0.83  \n",
      "1  0.801373                    0.50  \n",
      "2  0.929688                     NaN  \n",
      "3  0.002809                    0.00  \n",
      "4  0.970848                    1.00  \n",
      "5  0.973451                     NaN  \n",
      "6  0.973054                    1.00  \n",
      "7  1.000000                     NaN  \n",
      "8  0.319253                    0.50  \n",
      "9  0.946595                    0.00  \n"
     ]
    }
   ],
   "source": [
    "#merge with ChineseGender dataset results\n",
    "from tqdm import tqdm\n",
    "\n",
    "merged_truth_file = '/.../matched_results.csv'\n",
    "gudong_after_file = '/.../ChineseGender_cleaned1.txt'\n",
    "output_file = '/.../grantees.csv'\n",
    "\n",
    "gudong_after_df = pd.read_csv(gudong_after_file, sep='\\t', on_bad_lines='skip')\n",
    "print(\"成功读取股东数据，列名如下：\", gudong_after_df.columns)\n",
    "\n",
    "if 'fname' not in gudong_after_df.columns:\n",
    "    for col in gudong_after_df.columns:\n",
    "        if 'given' in col.lower() or 'en' in col.lower():\n",
    "            gudong_after_df.rename(columns={col: 'fname'}, inplace=True)\n",
    "\n",
    "gudong_after_df = gudong_after_df[['名', '汉字总数量', '汉字男性概率', 'fname', '拼音总数量', '拼音男性概率']]\n",
    "gudong_after_df_hanzi = gudong_after_df.drop_duplicates(subset='名', keep='first')\n",
    "gudong_after_df_pinyin = gudong_after_df.drop_duplicates(subset='fname', keep='first')\n",
    "\n",
    "hanzi_dict = gudong_after_df_hanzi.set_index('名')[['汉字总数量', '汉字男性概率']].to_dict(orient='index')\n",
    "pinyin_dict = gudong_after_df_pinyin.set_index('fname')[['拼音总数量', '拼音男性概率']].to_dict(orient='index')\n",
    "\n",
    "merged_truth_df = pd.read_csv(merged_truth_file, sep='\\t')\n",
    "print(\"成功读取真值数据，列名如下：\", merged_truth_df.columns)\n",
    "\n",
    "if 'given' not in merged_truth_df.columns:\n",
    "    print(\"错误：未找到 'given' 列，检查列名是否匹配\")\n",
    "    print(\"真值数据列名如下：\", merged_truth_df.columns)\n",
    "    raise ValueError(\"'given' 列不存在，请检查真值文件的内容！\")\n",
    "\n",
    "if 'givenEn' not in merged_truth_df.columns:\n",
    "    print(\"错误：未找到 'givenEn' 列，检查列名是否匹配\")\n",
    "    print(\"真值数据列名如下：\", merged_truth_df.columns)\n",
    "    raise ValueError(\"'givenEn' 列不存在，请检查真值文件的内容！\")\n",
    "\n",
    "total_rows = len(merged_truth_df)\n",
    "\n",
    "def process_merged_truth_file(chunk_size=10000):\n",
    "    for chunk in pd.read_csv(merged_truth_file, sep='\\t', chunksize=chunk_size):\n",
    "        chunk['汉字总数量'] = chunk['given'].map(lambda x: hanzi_dict.get(x, {}).get('汉字总数量'))\n",
    "        chunk['汉字男性概率'] = chunk['given'].map(lambda x: hanzi_dict.get(x, {}).get('汉字男性概率'))\n",
    "        chunk['拼音总数量'] = chunk['givenEn'].map(lambda x: pinyin_dict.get(x, {}).get('拼音总数量'))\n",
    "        chunk['拼音男性概率'] = chunk['givenEn'].map(lambda x: pinyin_dict.get(x, {}).get('拼音男性概率'))\n",
    "        yield chunk\n",
    "\n",
    "first_chunk = True\n",
    "with tqdm(total=total_rows, desc=\"Processing\", unit=\"rows\") as pbar:\n",
    "    for result_chunk in process_merged_truth_file():\n",
    "        result_chunk.to_csv(output_file, sep='\\t', index=False, mode='a', header=first_chunk)\n",
    "        first_chunk = False\n",
    "        pbar.update(len(result_chunk))\n",
    "\n",
    "result_df = pd.read_csv(output_file, sep='\\t')\n",
    "\n",
    "def calculate_genderize_predict_male(row):\n",
    "    if pd.isna(row['gender_genderize']) or pd.isna(row['probability']):\n",
    "        return None\n",
    "    if row['gender_genderize'] == 'male':\n",
    "        return row['probability']\n",
    "    elif row['gender_genderize'] == 'female':\n",
    "        return 1 - row['probability']\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "result_df['genderize_predict_male'] = result_df.apply(calculate_genderize_predict_male, axis=1)\n",
    "\n",
    "result_df.to_csv(output_file, sep='\\t', index=False)\n",
    "\n",
    "print(\"处理后的前10行：\")\n",
    "print(result_df.head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
